# Crear datasets
train_sf <- crear_dataset_espacial_optimizado(train_data, tipo_delito, columna_delito, cell_size)
test_sf <- crear_dataset_espacial_optimizado(test_data, tipo_delito, columna_delito, cell_size)
# Convertir a dataframe
train_df <- train_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
test_df <- test_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
# Entrenar modelo Random Forest
modelo_rf <- randomForest(
tiene_delito ~ x_norm + y_norm + dist_centro_norm + densidad_local_norm + cuadrante,
data = train_df,
ntree = ntree,
mtry = mtry,
importance = TRUE,
do.trace = FALSE
)
# Predicciones (probabilidades)
pred_prob <- predict(modelo_rf, test_df, type = "prob")[, "1"]
# Calcular AUC
roc_obj <- roc(test_df$tiene_delito, pred_prob, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
# Métricas adicionales
pred_class <- factor(ifelse(pred_prob > 0.5, "1", "0"), levels = c("0", "1"))
cm <- confusionMatrix(pred_class, test_df$tiene_delito, positive = "1")
# Importancia de variables
importancia <- importance(modelo_rf)
importancia_df <- data.frame(
Variable = rownames(importancia),
MeanDecreaseAccuracy = importancia[, "MeanDecreaseAccuracy"],
MeanDecreaseGini = importancia[, "MeanDecreaseGini"]
)
return(list(
auc = auc_val,
accuracy = cm$overall["Accuracy"],
sensitivity = cm$byClass["Sensitivity"],
specificity = cm$byClass["Specificity"],
precision = cm$byClass["Pos Pred Value"],
cell_size = cell_size,
n_celdas_train = nrow(train_sf),
n_celdas_test = nrow(test_sf),
casos_positivos = sum(train_df$tiene_delito == "1"),
casos_negativos = sum(train_df$tiene_delito == "0"),
modelo = modelo_rf,
train_data = train_sf,
test_data = test_sf,
importancia = importancia_df,
oob_error = modelo_rf$err.rate[modelo_rf$ntree, "OOB"],
error = NULL
))
}
regLog_final_H = entrenar_evaluar_logistica(preTrain, Validation, "Hurto", "tipo", 50)
regLog_final_R = entrenar_evaluar_logistica(preTrain, Validation, "Robo", "tipo", 50)
RF_final_H = entrenar_evaluar_randomforest(preTrain, Validation, "Hurto", "tipo", 50, 50, 2)
RF_final_R = entrenar_evaluar_randomforest(preTrain, Validation, "Robo", "tipo", 50, 50, 2)
XG_final_H = entrenar_evaluar_xgboost(preTrain, Validation, "Hurto", "tipo", 50, 50, 0.1,6)
XG_final_R = entrenar_evaluar_xgboost(preTrain, Validation, "Robo", "tipo", 50, 50, 0.1,6)
# =============================================================================
# FUNCIÓN PARA XGBOOST
# =============================================================================
entrenar_evaluar_xgboost <- function(train_data, test_data, tipo_delito, columna_delito, cell_size, nrounds, eta, max_depth) {
# Crear datasets
train_sf <- crear_dataset_espacial_optimizado(train_data, tipo_delito, columna_delito, cell_size)
test_sf <- crear_dataset_espacial_optimizado(test_data, tipo_delito, columna_delito, cell_size)
# Convertir a dataframe
train_df <- train_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
test_df <- test_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
# Preparar datos para XGBoost
train_matrix <- model.matrix(tiene_delito ~ . - 1, data = train_df)
test_matrix <- model.matrix(tiene_delito ~ . - 1, data = test_df)
# Labels (0 y 1)
train_labels <- as.numeric(as.character(train_df$tiene_delito))
test_labels <- as.numeric(as.character(test_df$tiene_delito))
# Crear matrices DMatrix para XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)
# Parámetros para XGBoost
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = max_depth,
eta = eta,
subsample = 0.8,
colsample_bytree = 0.8,
verbosity = 0  # Silenciar output
)
modelo_xgb <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
watchlist = list(train = dtrain, test = dtest),
verbose = 0,  # Silenciar output
early_stopping_rounds = 10,
print_every_n = 0  # No imprimir progreso
)
# Predicciones (probabilidades)
pred_prob <- predict(modelo_xgb, dtest)
# Calcular AUC
roc_obj <- roc(test_df$tiene_delito, pred_prob, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
# Métricas adicionales
pred_class <- factor(ifelse(pred_prob > 0.5, "1", "0"), levels = c("0", "1"))
cm <- confusionMatrix(pred_class, test_df$tiene_delito, positive = "1")
# Importancia de variables
importancia <- xgb.importance(model = modelo_xgb)
return(list(
auc = auc_val,
accuracy = cm$overall["Accuracy"],
sensitivity = cm$byClass["Sensitivity"],
specificity = cm$byClass["Specificity"],
precision = cm$byClass["Pos Pred Value"],
cell_size = cell_size,
n_celdas_train = nrow(train_sf),
n_celdas_test = nrow(test_sf),
casos_positivos = sum(train_df$tiene_delito == "1"),
casos_negativos = sum(train_df$tiene_delito == "0"),
modelo = modelo_xgb,
train_data = train_sf,
test_data = test_sf,
importancia = importancia,
best_nrounds = best_nrounds,
cv_result = cv_result,
error = NULL
))
}
regLog_final_H = entrenar_evaluar_logistica(preTrain, Validation, "Hurto", "tipo", 50)
regLog_final_R = entrenar_evaluar_logistica(preTrain, Validation, "Robo", "tipo", 50)
RF_final_H = entrenar_evaluar_randomforest(preTrain, Validation, "Hurto", "tipo", 50, 50, 2)
RF_final_R = entrenar_evaluar_randomforest(preTrain, Validation, "Robo", "tipo", 50, 50, 2)
XG_final_H = entrenar_evaluar_xgboost(preTrain, Validation, "Hurto", "tipo", 50, 50, 0.1,6)
XG_final_R = entrenar_evaluar_xgboost(preTrain, Validation, "Robo", "tipo", 50, 50, 0.1,6)
regLog_final_H = entrenar_evaluar_logistica(preTrain, Validation, "Hurto", "tipo", 50)
regLog_final_R = entrenar_evaluar_logistica(preTrain, Validation, "Robo", "tipo", 50)
RF_final_H = entrenar_evaluar_randomforest(preTrain, Validation, "Hurto", "tipo", 50, 50, 2)
RF_final_R = entrenar_evaluar_randomforest(preTrain, Validation, "Robo", "tipo", 50, 50, 2)
XG_final_H = entrenar_evaluar_xgboost(preTrain, Validation, "Hurto", "tipo", 50, 50, 0.1,6)
XG_final_R = entrenar_evaluar_xgboost(preTrain, Validation, "Robo", "tipo", 50, 50, 0.1,6)
# =============================================================================
# FUNCIÓN PARA XGBOOST
# =============================================================================
entrenar_evaluar_xgboost <- function(train_data, test_data, tipo_delito, columna_delito, cell_size, nrounds, eta, max_depth) {
# Crear datasets
train_sf <- crear_dataset_espacial_optimizado(train_data, tipo_delito, columna_delito, cell_size)
test_sf <- crear_dataset_espacial_optimizado(test_data, tipo_delito, columna_delito, cell_size)
# Convertir a dataframe
train_df <- train_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
test_df <- test_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
# Preparar datos para XGBoost
train_matrix <- model.matrix(tiene_delito ~ . - 1, data = train_df)
test_matrix <- model.matrix(tiene_delito ~ . - 1, data = test_df)
# Labels (0 y 1)
train_labels <- as.numeric(as.character(train_df$tiene_delito))
test_labels <- as.numeric(as.character(test_df$tiene_delito))
# Crear matrices DMatrix para XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)
# Parámetros para XGBoost
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = max_depth,
eta = eta,
subsample = 0.8,
colsample_bytree = 0.8,
verbosity = 0  # Silenciar output
)
modelo_xgb <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
watchlist = list(train = dtrain, test = dtest),
verbose = 0,  # Silenciar output
early_stopping_rounds = 10,
print_every_n = 0  # No imprimir progreso
)
# Predicciones (probabilidades)
pred_prob <- predict(modelo_xgb, dtest)
# Calcular AUC
roc_obj <- roc(test_df$tiene_delito, pred_prob, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
# Métricas adicionales
pred_class <- factor(ifelse(pred_prob > 0.5, "1", "0"), levels = c("0", "1"))
cm <- confusionMatrix(pred_class, test_df$tiene_delito, positive = "1")
# Importancia de variables
importancia <- xgb.importance(model = modelo_xgb)
return(list(
auc = auc_val,
accuracy = cm$overall["Accuracy"],
sensitivity = cm$byClass["Sensitivity"],
specificity = cm$byClass["Specificity"],
precision = cm$byClass["Pos Pred Value"],
cell_size = cell_size,
n_celdas_train = nrow(train_sf),
n_celdas_test = nrow(test_sf),
casos_positivos = sum(train_df$tiene_delito == "1"),
casos_negativos = sum(train_df$tiene_delito == "0"),
modelo = modelo_xgb,
train_data = train_sf,
test_data = test_sf,
importancia = importancia,
nrounds = nrounds,
cv_result = cv_result,
error = NULL
))
}
regLog_final_H = entrenar_evaluar_logistica(preTrain, Validation, "Hurto", "tipo", 50)
regLog_final_R = entrenar_evaluar_logistica(preTrain, Validation, "Robo", "tipo", 50)
RF_final_H = entrenar_evaluar_randomforest(preTrain, Validation, "Hurto", "tipo", 50, 50, 2)
RF_final_R = entrenar_evaluar_randomforest(preTrain, Validation, "Robo", "tipo", 50, 50, 2)
XG_final_H = entrenar_evaluar_xgboost(preTrain, Validation, "Hurto", "tipo", 50, 50, 0.1,6)
XG_final_R = entrenar_evaluar_xgboost(preTrain, Validation, "Robo", "tipo", 50, 50, 0.1,6)
# =============================================================================
# FUNCIÓN PARA XGBOOST
# =============================================================================
entrenar_evaluar_xgboost <- function(train_data, test_data, tipo_delito, columna_delito, cell_size, nrounds, eta, max_depth) {
# Crear datasets
train_sf <- crear_dataset_espacial_optimizado(train_data, tipo_delito, columna_delito, cell_size)
test_sf <- crear_dataset_espacial_optimizado(test_data, tipo_delito, columna_delito, cell_size)
# Convertir a dataframe
train_df <- train_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
test_df <- test_sf %>%
st_drop_geometry() %>%
dplyr::select(tiene_delito, x_norm, y_norm, dist_centro_norm,
densidad_local_norm, cuadrante)
# Preparar datos para XGBoost
train_matrix <- model.matrix(tiene_delito ~ . - 1, data = train_df)
test_matrix <- model.matrix(tiene_delito ~ . - 1, data = test_df)
# Labels (0 y 1)
train_labels <- as.numeric(as.character(train_df$tiene_delito))
test_labels <- as.numeric(as.character(test_df$tiene_delito))
# Crear matrices DMatrix para XGBoost
dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)
dtest <- xgb.DMatrix(data = test_matrix, label = test_labels)
# Parámetros para XGBoost
params <- list(
objective = "binary:logistic",
eval_metric = "auc",
max_depth = max_depth,
eta = eta,
subsample = 0.8,
colsample_bytree = 0.8,
verbosity = 0  # Silenciar output
)
modelo_xgb <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
watchlist = list(train = dtrain, test = dtest),
verbose = 0,  # Silenciar output
early_stopping_rounds = 10,
print_every_n = 0  # No imprimir progreso
)
# Predicciones (probabilidades)
pred_prob <- predict(modelo_xgb, dtest)
# Calcular AUC
roc_obj <- roc(test_df$tiene_delito, pred_prob, quiet = TRUE)
auc_val <- as.numeric(auc(roc_obj))
# Métricas adicionales
pred_class <- factor(ifelse(pred_prob > 0.5, "1", "0"), levels = c("0", "1"))
cm <- confusionMatrix(pred_class, test_df$tiene_delito, positive = "1")
# Importancia de variables
importancia <- xgb.importance(model = modelo_xgb)
return(list(
auc = auc_val,
accuracy = cm$overall["Accuracy"],
sensitivity = cm$byClass["Sensitivity"],
specificity = cm$byClass["Specificity"],
precision = cm$byClass["Pos Pred Value"],
cell_size = cell_size,
n_celdas_train = nrow(train_sf),
n_celdas_test = nrow(test_sf),
casos_positivos = sum(train_df$tiene_delito == "1"),
casos_negativos = sum(train_df$tiene_delito == "0"),
modelo = modelo_xgb,
train_data = train_sf,
test_data = test_sf,
importancia = importancia,
nrounds = nrounds,
error = NULL
))
}
regLog_final_H = entrenar_evaluar_logistica(preTrain, Validation, "Hurto", "tipo", 50)
regLog_final_R = entrenar_evaluar_logistica(preTrain, Validation, "Robo", "tipo", 50)
RF_final_H = entrenar_evaluar_randomforest(preTrain, Validation, "Hurto", "tipo", 50, 50, 2)
RF_final_R = entrenar_evaluar_randomforest(preTrain, Validation, "Robo", "tipo", 50, 50, 2)
XG_final_H = entrenar_evaluar_xgboost(preTrain, Validation, "Hurto", "tipo", 50, 50, 0.1,6)
XG_final_R = entrenar_evaluar_xgboost(preTrain, Validation, "Robo", "tipo", 50, 50, 0.1,6)
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
View(datos2023)
View(datos2022)
dplyr
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
install.packages(dplyr)
install.packages("dplyr")
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
#Cargo datos
datos2022 <- read.csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read.csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-"id.mapa")
#Cargo datos
datos2022 <- read_csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read_csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
#Cargo librerias
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(terra)
library(sf)
library("leaflet")
library(purrr)
library(MASS)
library(raster)
library(caret)
library(pROC)
library(randomForest)
library(xgboost)
#Cargo datos
datos2022 <- read_csv("./delitos_2022.csv")
datos2023 <- read_csv("./delitos_2023.csv")
datos2024 <- read_csv("./delitos_2024.csv")
#Junto todo
datos2022$fecha <- as.Date(datos2022$fecha)
datos2023$fecha <- as.Date(datos2023$fecha)
datos2024$fecha <- as.Date(datos2024$fecha)
datos2022$franja <- as.numeric(datos2022$franja)
datos2023$franja <- as.numeric(datos2023$franja)
datos2024$franja <- as.numeric(datos2024$franja)
datos2022 <- datos2022 %>% select(-id.mapa)
